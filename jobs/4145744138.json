{
    "job_id": "4145744138",
    "title": "Data Scientist",
    "company": "Protium",
    "location": "Mumbai, Maharashtra, India",
    "description": "We are seeking a highly skilled and motivated Data Scientist (Feature Engineering) to join our growing team. In this role, you will play a crucial part in developing and optimizing our data processing pipeline. You will be responsible for converting existing Python-based data parsing and feature engineering code to be compatible with GPU acceleration and Apache Spark for large-scale data processing.\n\n\n\n\nResponsibilities:\n\n\n\n\nAnalyze and understand existing Python code for data parsing and feature engineering.\nRefactor and optimize the code to leverage GPU acceleration using libraries like CUDA or Numba.\nConvert the code to be compatible with Apache Spark, enabling distributed processing on a cluster.\nDevelop and implement efficient feature engineering techniques for various data types (e.g., text, numerical, categorical).\nEnsure the scalability, performance, and reliability of the data processing pipeline.\nCollaborate with other data scientists and engineers to integrate the pipeline into our machine learning workflows.\nStay up-to-date with the latest advancements in data science, feature engineering, and distributed computing.\n\n\n\n\nQualifications:\n\n\n\n\nOverall work experience between 1-4 years\nStrong programming skills in Python, with experience in data science libraries (NumPy, Pandas, Scikit-learn).\nProven experience in feature engineering, including feature extraction, transformation, and selection.\nHands-on experience with GPU programming (CUDA, Numba, or similar).\nSolid understanding of Spark / Dask and its ecosystem (Spark DataFrames, Spark SQL).\nExperience with data parsing and handling different data formats.\nPassion for problem-solving through code: You should enjoy the challenge of breaking down complex problems into smaller, manageable pieces and finding creative solutions.\nAbility to write structured and reusable code: You should write code that is clean, well-documented, and easy to maintain.\nFluency in database-related operations: You should have a good understanding of SQL and be familiar with working with databases like MySQL, PostgreSQL, or NoSQL databases.\n\n\n\n\nDesirable:\n\nFamiliarity with cloud computing platforms (AWS, GCP, Azure).\nKnowledge of DevOps practices (Git, testing, CI/CD).\nExperience in Lending Industry.\nShow more ",
    "link": "https://in.linkedin.com/jobs/view/data-scientist-at-protium-4145744138?position=36&pageNum=0&refId=0TjBuuvTuSfYzNBXKQFVLw%3D%3D&trackingId=fjL6v5OA581wz29hW8dirg%3D%3D"
}